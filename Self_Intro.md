# Intro

I am a Data Engineer with over 3 years of experience in building and maintaining data solutions, focusing on technologies like Databricks, Azure Data Factory, ADLS Blob Storage, PySpark, SQL, and Python. My expertise includes developing scalable data pipelines to automate data ingestion, transformation, and loading for large datasets, both in batch and real-time. I have implemented efficient data processing workflows in PySpark within Databricks, leveraging ADLS Blob Storage to handle large-scale data efficiently.

I have been responsible for writing optimized SQL queries for data extraction and transformation from ADLS Blob Storage, ensuring high performance for reporting and analytics. In addition, I have built data workflows in Azure Data Factory to move data between ADLS and various other sources, automating the entire process. Utilizing Python, I have scripted and automated transformations on datasets, improving pipeline efficiency while reducing manual intervention.

Throughout my projects, I have ensured smooth collaboration by managing code versioning with GitHub and tracking tasks using Jira in an agile environment. I have also monitored and optimized Databricks clusters for better resource utilization, minimizing costs while ensuring high performance. Furthermore, I have collaborated with cross-functional teams to implement best practices for data storage and processing in ADLS Blob Storage, maintaining data quality, accuracy, and consistency across various layers in the architecture.

Developed scalable data pipelines in Databricks and Azure Data Factory, automating data ingestion, transformation, and loading for large datasets stored in ADLS Blob Storage, handling both batch and real-time processing.

Implemented data processing workflows in PySpark within Databricks to read, process, and write large datasets efficiently to and from ADLS Blob Storage.

Created optimized SQL queries for data extraction and transformation from ADLS Blob Storage, ensuring high performance for downstream reporting and analytics.

Built and managed workflows in Azure Data Factory to move data between ADLS Blob Storage and various other sources and destinations, automating data flows seamlessly.

Utilized Python for scripting and automating data transformations on datasets stored in ADLS Blob Storage, enhancing pipeline efficiency and reducing manual tasks.

Monitored and optimized Databricks jobs, improving cluster utilization and minimizing the cost of processing large datasets stored in ADLS Blob Storage.

Managed code versioning using GitHub, ensuring smooth collaboration and proper version control across multiple development teams.

Used Jira for agile project tracking and task management, contributing to the successful and timely delivery of data engineering projects.

Collaborated with cross-functional teams to implement best practices for storing, organizing, and processing data in ADLS Blob Storage, ensuring optimal data access and retrieval performance.
